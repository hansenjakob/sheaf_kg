{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/gebhart/projects/sheaf_kg')\n",
    "\n",
    "import sheaf_kg.harmonic_extension as harmonic_extension\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FB15k-237'\n",
    "num_test = 1000\n",
    "model_name = 'SheafE_multisection_50_sections_1000epochs_64dim_SoftplusLossloss_1235seed_20210202-0825'\n",
    "save_loc = '/home/gebhart/projects/sheaf_kg/data/{}/{}/trained_model.pkl'.format(dataset,model_name)\n",
    "# q2b_path = '/home/gebhart/projects/sheaf_kg/data/{}-q2b'.format(dataset)\n",
    "q2b_path = '/home/gebhart/projects/sheaf_kg/data/{}-betae'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_structures = [('e', ('r', 'r')), ('e', ('r', 'r', 'r')), (('e', ('r',)), ('e', ('r',))), (('e', ('r',)), ('e', ('r',)), ('e', ('r',))), (('e', ('r', 'r')), ('e', ('r',))), ((('e', ('r',)), ('e', ('r',))), ('r',))]\n",
    "\n",
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pykeen.models import StructuredEmbedding\n",
    "from pykeen.models.base import _OldAbstractModel\n",
    "from pykeen.nn import Embedding\n",
    "from pykeen.losses import Loss\n",
    "from pykeen.nn.init import xavier_uniform_\n",
    "from pykeen.regularizers import Regularizer\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.typing import DeviceHint\n",
    "from pykeen.utils import compose\n",
    "\n",
    "from torch.nn import functional\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class ModifiedSE(_OldAbstractModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        triples_factory: TriplesFactory,\n",
    "        embedding_dim: int = 64,\n",
    "        scoring_fct_norm: int = 2,\n",
    "        num_sections: int = 50,\n",
    "        loss: Optional[Loss] = None,\n",
    "        preferred_device: DeviceHint = None,\n",
    "        random_seed: Optional[int] = None,\n",
    "        regularizer: Optional[Regularizer] = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"Initialize SE.\n",
    "\n",
    "        :param embedding_dim: The entity embedding dimension $d$. Is usually $d \\in [50, 300]$.\n",
    "        :param scoring_fct_norm: The $l_p$ norm. Usually 1 for SE.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            triples_factory=triples_factory,\n",
    "            loss=loss,\n",
    "            preferred_device=preferred_device,\n",
    "            random_seed=random_seed,\n",
    "            regularizer=regularizer,\n",
    "        )\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_sections = num_sections\n",
    "        self.scoring_fct_norm = scoring_fct_norm\n",
    "\n",
    "        esize = (triples_factory.num_entities, num_sections, embedding_dim)\n",
    "        self.ent_embeddings = Parameter(nn.init.xavier_uniform_(torch.empty(esize, device=preferred_device, dtype=torch.float32)),requires_grad=True)\n",
    "\n",
    "        tsize = (triples_factory.num_relations, embedding_dim, embedding_dim)\n",
    "        self.left_embeddings = Parameter(nn.init.xavier_uniform_(torch.empty(tsize, device=preferred_device, dtype=torch.float32)),requires_grad=True)\n",
    "        self.right_embeddings = Parameter(nn.init.xavier_uniform_(torch.empty(tsize, device=preferred_device, requires_grad=True, dtype=torch.float32)),requires_grad=True)\n",
    "\n",
    "    def _reset_parameters_(self):  # noqa: D102\n",
    "        self.ent_embeddings = nn.init.xavier_uniform_(self.ent_embeddings)\n",
    "        self.left_embeddings = nn.init.xavier_uniform_(self.left_embeddings)\n",
    "        self.right_embeddings = nn.init.xavier_uniform_(self.right_embeddings)\n",
    "\n",
    "\n",
    "    def score_hrt(self, hrt_batch: torch.LongTensor) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        h = torch.index_select(self.ent_embeddings, 0, hrt_batch[:, 0]).view(-1, self.embedding_dim, self.num_sections)\n",
    "        rel_h = torch.index_select(self.left_embeddings, 0, hrt_batch[:, 1])\n",
    "        rel_t = torch.index_select(self.right_embeddings, 0, hrt_batch[:, 1])\n",
    "        t = torch.index_select(self.ent_embeddings, 0, hrt_batch[:, 2]).view(-1, self.embedding_dim, self.num_sections)\n",
    "\n",
    "        # Project entities\n",
    "        proj_h = rel_h @ h\n",
    "        proj_t = rel_t @ t\n",
    "        scores = -torch.norm(proj_h - proj_t, dim=(1,2), p=self.scoring_fct_norm)\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def score_t(self, hr_batch: torch.LongTensor, slice_size: int = None) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        h = torch.index_select(self.ent_embeddings, 0, hr_batch[:, 0]).view(-1, self.embedding_dim, self.num_sections)\n",
    "        rel_h = torch.index_select(self.left_embeddings, 0, hr_batch[:, 1])\n",
    "        rel_t = torch.index_select(self.right_embeddings, 0, hr_batch[:, 1])\n",
    "        rel_t = rel_t.view(-1, 1, self.embedding_dim, self.embedding_dim)\n",
    "        t_all = self.ent_embeddings.view(1, -1, self.embedding_dim, self.num_sections)\n",
    "\n",
    "        if slice_size is not None:\n",
    "            raise ValueError('Not implemented')\n",
    "\n",
    "        else:\n",
    "            # Project entities\n",
    "            proj_h = rel_h @ h\n",
    "            proj_t = rel_t @ t_all\n",
    "\n",
    "        scores = -torch.norm(proj_h[:, None, :, :] - proj_t[:, :, :, :], dim=(-1,-2), p=self.scoring_fct_norm)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def score_h(self, rt_batch: torch.LongTensor, slice_size: int = None) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        h_all = self.ent_embeddings.view(1, -1, self.embedding_dim, self.num_sections)\n",
    "        rel_h = torch.index_select(self.left_embeddings, 0, rt_batch[:, 0])\n",
    "        rel_h = rel_h.view(-1, 1, self.embedding_dim, self.embedding_dim)\n",
    "        rel_t = torch.index_select(self.right_embeddings, 0, rt_batch[:, 0])\n",
    "        t = torch.index_select(self.ent_embeddings, 0, rt_batch[:, 1]).view(-1, self.embedding_dim, self.num_sections)\n",
    "\n",
    "        if slice_size is not None:\n",
    "            raise ValueError('Not implemented')\n",
    "        else:\n",
    "            # Project entities\n",
    "            proj_h = rel_h @ h_all\n",
    "            proj_t = rel_t @ t\n",
    "\n",
    "        scores = -torch.norm(proj_h[:, :, :, :] - proj_t[:, None, :, :], dim=(-1,-2), p=self.scoring_fct_norm)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_loc).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're trying to map triples with 30 entities and 0 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "In total 28 from 20466 triples were filtered out\n"
     ]
    }
   ],
   "source": [
    "ds = pykeen.datasets.get_dataset(dataset=dataset)\n",
    "training = ds.training.mapped_triples\n",
    "relid2label = ds.training.relation_id_to_label \n",
    "label2relid = {v:k for k,v in relid2label.items()}\n",
    "\n",
    "entid2label = ds.training.entity_id_to_label \n",
    "label2entid = {v:k for k,v in entid2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(q2b_path,'test-queries.pkl'), 'rb') as f:\n",
    "    test_queries = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(q2b_path,'test-easy-answers.pkl'), 'rb') as f:\n",
    "    test_answers = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(q2b_path,'id2rel.pkl'), 'rb') as f:\n",
    "    id2rel = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(q2b_path,'id2ent.pkl'), 'rb') as f:\n",
    "    id2ent = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ent(e):\n",
    "    return label2entid[id2ent[e]]\n",
    "def map_rel(r):\n",
    "    orientation = 1\n",
    "    relname = id2rel[r]\n",
    "    if relname[0] == '-':\n",
    "        orientation = -1\n",
    "    return label2relid[relname[1:]], orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = 25\n",
    "def L_p(query, model):\n",
    "    '''query of form ('e', ('r', 'r', ... , 'r')).\n",
    "    here we assume 2 or more relations are present so 2p or greater\n",
    "    '''\n",
    "    ent = map_ent(query[0])\n",
    "    invs = []\n",
    "    rels = []\n",
    "    for r in query[1]:\n",
    "        mapped_id, orientation = map_rel(r) \n",
    "        rels.append(mapped_id)\n",
    "        invs.append(orientation)\n",
    "    n_path_ents = len(rels)\n",
    "    \n",
    "    edge_indices = np.concatenate([np.arange(0,n_path_ents)[:,np.newaxis].T, np.arange(1,n_path_ents+1)[:,np.newaxis].T], axis=0)\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    restrictions = np.empty((len(rels), 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "#     restrictions[:,0,:,:] = left_restrictions\n",
    "#     restrictions[:,1,:,:] = right_restrictions\n",
    "    for invix in range(len(invs)):\n",
    "        if invix == -1:\n",
    "            restrictions[:,0,:,:] = right_restrictions\n",
    "            restrictions[:,1,:,:] = left_restrictions\n",
    "        else:\n",
    "            restrictions[:,0,:,:] = left_restrictions\n",
    "            restrictions[:,1,:,:] = right_restrictions\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor([ent])\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor)\n",
    "#     source_embeddings = source_embeddings[:,section,:].view(-1, model.embedding_dim).detach().numpy()\n",
    "    source_embeddings = torch.mean(source_embeddings, dim=1).view(-1, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    B = np.array([0,n_path_ents],np.int)\n",
    "    U = np.array(range(1,n_path_ents),np.int)\n",
    "    source_vertices = [0]\n",
    "    target_vertices = [1]\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    return LSchur, source_vertices, target_vertices, source_embeddings\n",
    "\n",
    "def L_i(query, model):\n",
    "    '''query of form (('e', ('r',)), ('e', ('r',)), ... , ('e', ('r',)))'''\n",
    "    num_intersects = len(query)\n",
    "    ents = []\n",
    "    rels = []\n",
    "    invs = []\n",
    "    for pair in query:\n",
    "        ents.append(map_ent(pair[0]))\n",
    "        rel, inv = map_rel(pair[1][0])\n",
    "        rels.append(rel)\n",
    "        invs.append(inv)\n",
    "    n_ents = num_intersects\n",
    "    edge_indices = np.concatenate([np.arange(0,n_ents)[:,np.newaxis].T, np.full(n_ents,n_ents)[:,np.newaxis].T], axis=0)\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "\n",
    "    restrictions = np.empty((len(rels), 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "#     restrictions[:,0,:,:] = left_restrictions\n",
    "#     restrictions[:,1,:,:] = right_restrictions\n",
    "    for invix in range(len(invs)):\n",
    "        if invix == -1:\n",
    "            restrictions[:,0,:,:] = right_restrictions\n",
    "            restrictions[:,1,:,:] = left_restrictions\n",
    "        else:\n",
    "            restrictions[:,0,:,:] = left_restrictions\n",
    "            restrictions[:,1,:,:] = right_restrictions\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor)\n",
    "#     source_embeddings = source_embeddings[:,section,:].view(-1, model.embedding_dim).detach().numpy()\n",
    "    source_embeddings = torch.mean(source_embeddings, dim=1).view(-1, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    L = harmonic_extension.Laplacian(edge_indices, restrictions)\n",
    "    source_vertices = np.arange(n_ents)\n",
    "    target_vertices = [n_ents]\n",
    "    return L, source_vertices, target_vertices, source_embeddings\n",
    "\n",
    "def L_ip(query, model):\n",
    "    '''query of form ((('e', ('r',)), ('e', ('r',))), ('r',))'''\n",
    "    ents = [map_ent(t[0]) for t in query[0]]\n",
    "    rel0, inv0 = map_rel(query[0][0][1][0])\n",
    "    rel1, inv1 = map_rel(query[0][1][1][0])\n",
    "    rel2, inv2 = map_rel(query[1][0])\n",
    "    rels = [rel0, rel1, rel2]\n",
    "    invs = [inv0, inv1, inv2]\n",
    "    n_ents = len(ents)\n",
    "    edge_indices = np.array([[0,2],[1,2],[2,3]],np.int).T\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    restrictions = np.empty((len(rels), 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "#     restrictions[:,0,:,:] = left_restrictions\n",
    "#     restrictions[:,1,:,:] = right_restrictions\n",
    "    for invix in range(len(invs)):\n",
    "        if invix == -1:\n",
    "            restrictions[:,0,:,:] = right_restrictions\n",
    "            restrictions[:,1,:,:] = left_restrictions\n",
    "        else:\n",
    "            restrictions[:,0,:,:] = left_restrictions\n",
    "            restrictions[:,1,:,:] = right_restrictions\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor)\n",
    "#     source_embeddings = source_embeddings[:,section,:].view(-1, model.embedding_dim).detach().numpy()\n",
    "    source_embeddings = torch.mean(source_embeddings, dim=1).view(-1, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    B = np.array([0,2,3],np.int)\n",
    "    U = np.array([1],np.int)\n",
    "    source_vertices = [0,1]\n",
    "    target_vertices = [2]\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    return LSchur, source_vertices, target_vertices, source_embeddings\n",
    "    \n",
    "def L_pi(query, model):\n",
    "    '''query of form (('e', ('r', 'r')), ('e', ('r',)))'''\n",
    "    ents = [map_ent(t[0]) for t in query]\n",
    "    rel0, inv0 = map_rel(query[0][1][0])\n",
    "    rel1, inv1 = map_rel(query[0][1][1])\n",
    "    rel2, inv2 = map_rel(query[1][1][0])\n",
    "    rels = [rel0, rel1, rel2]\n",
    "    invs = [inv0, inv1, inv2]\n",
    "    n_ents = len(ents)\n",
    "    edge_indices = np.array([[0,2],[2,3],[1,3]],np.int).T\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    restrictions = np.empty((len(rels), 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "#     restrictions[:,0,:,:] = left_restrictions\n",
    "#     restrictions[:,1,:,:] = right_restrictions\n",
    "    for invix in range(len(invs)):\n",
    "        if invix == -1:\n",
    "            restrictions[:,0,:,:] = right_restrictions\n",
    "            restrictions[:,1,:,:] = left_restrictions\n",
    "        else:\n",
    "            restrictions[:,0,:,:] = left_restrictions\n",
    "            restrictions[:,1,:,:] = right_restrictions\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor)\n",
    "#     source_embeddings = source_embeddings[:,section,:].view(-1, model.embedding_dim).detach().numpy()\n",
    "    source_embeddings = torch.mean(source_embeddings, dim=1).view(-1, model.embedding_dim).detach().numpy()\n",
    "    \n",
    "    B = np.array([0,1,3],np.int)\n",
    "    U = np.array([2],np.int)\n",
    "    source_vertices = [0,1]\n",
    "    target_vertices = [2]\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    return LSchur, source_vertices, target_vertices, source_embeddings\n",
    "\n",
    "query_name_fn_dict = {'2p': L_p, '3p':L_p, '2i': L_i, '3i':L_i, 'ip':L_ip, 'pi': L_pi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<01:04, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 28.31it/s]\n",
      "  0%|          | 3/1000 [00:00<00:34, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 21.25it/s]\n",
      "  1%|          | 6/1000 [00:00<00:17, 55.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.36it/s]\n",
      "  1%|          | 7/1000 [00:00<00:15, 65.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 81.78it/s]\n",
      "  0%|          | 5/1000 [00:00<00:21, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r', 'r')), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 32.53it/s]\n",
      "  0%|          | 5/1000 [00:00<00:28, 34.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ((('e', ('r',)), ('e', ('r',))), ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# target_embeddings = model.ent_embeddings[:,section,:].view(-1, model.embedding_dim).detach().numpy().T\n",
    "target_embeddings = torch.mean(model.ent_embeddings, dim=1).view(-1, model.embedding_dim).detach().numpy().T\n",
    "allhits1 = []\n",
    "allhits3 = []\n",
    "allhits5 = []\n",
    "allhits10 = []\n",
    "allmrr = []\n",
    "query_names = []\n",
    "for query_structure in query_structures:\n",
    "    print('Running query : {}'.format(query_structure))\n",
    "    query_name = query_name_dict[query_structure]\n",
    "    query_names.append(query_name)\n",
    "    fn = query_name_fn_dict[query_name]\n",
    "    hits1 = 0.\n",
    "    hits3 = 0.\n",
    "    hits5 = 0.\n",
    "    hits10 = 0.\n",
    "    mrr = 0.\n",
    "    cnt = 0\n",
    "    queries = list(test_queries[query_structure])\n",
    "    for query in tqdm(queries[:num_test]):\n",
    "        if len(test_answers[query]) > 0:\n",
    "            # we have a non-trivial \"easy\" query\n",
    "            answers = [map_ent(a) for a in test_answers[query]]\n",
    "            L, source_vertices, target_vertices, source_embeddings = fn(query, model)\n",
    "            Q = harmonic_extension.compute_costs(L,source_vertices,target_vertices,source_embeddings.flatten(),target_embeddings,source_embeddings.shape[1])\n",
    "            sortd = np.sort(Q)\n",
    "            idxleft = np.searchsorted(sortd, Q[answers], side='left') + 1\n",
    "            idxright = np.searchsorted(sortd, Q[answers], side='right') + 1\n",
    "#             idxright = idxleft # throw this for optimistic ranking\n",
    "            hits1 += ((np.mean(idxleft <= 1) + np.mean(idxright <= 1)) / 2.)\n",
    "            hits3 += ((np.mean(idxleft <= 3) + np.mean(idxright <= 3)) / 2.)\n",
    "            hits5 += ((np.mean(idxleft <= 5) + np.mean(idxright <= 5)) / 2.)\n",
    "            hits10 += ((np.mean(idxleft <= 10) + np.mean(idxright <= 10)) / 2.)\n",
    "            mrr += ((np.mean(1./idxleft) + np.mean(1./idxright)) / 2.)\n",
    "            cnt += 1\n",
    "    if cnt > 0:\n",
    "        allhits1.append(hits1/cnt)\n",
    "        allhits3.append(hits3/cnt)\n",
    "        allhits5.append(hits5/cnt)\n",
    "        allhits10.append(hits10/cnt)\n",
    "        allmrr.append(mrr/cnt)\n",
    "    else:\n",
    "        default = 0.\n",
    "        allhits1.append(default)\n",
    "        allhits3.append(default)\n",
    "        allhits5.append(default)\n",
    "        allhits10.append(default)\n",
    "        allmrr.append(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['hits@1', 'hits@3', 'hits@5', 'hits@10', 'mrr']\n",
    "df = pd.DataFrame(np.array([allhits1, allhits3, allhits5, allhits10, allmrr]).T,columns=cols, index=query_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2p</th>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.098226</td>\n",
       "      <td>0.073679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3p</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.051208</td>\n",
       "      <td>0.061706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2i</th>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.030328</td>\n",
       "      <td>0.046770</td>\n",
       "      <td>0.108958</td>\n",
       "      <td>0.093733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3i</th>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.042664</td>\n",
       "      <td>0.065942</td>\n",
       "      <td>0.144193</td>\n",
       "      <td>0.104747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pi</th>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>0.024361</td>\n",
       "      <td>0.060081</td>\n",
       "      <td>0.072847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.080585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@1    hits@3    hits@5   hits@10       mrr\n",
       "2p  0.003393  0.025180  0.042993  0.098226  0.073679\n",
       "3p  0.000759  0.010170  0.018110  0.051208  0.061706\n",
       "2i  0.004543  0.030328  0.046770  0.108958  0.093733\n",
       "3i  0.005219  0.042664  0.065942  0.144193  0.104747\n",
       "pi  0.003386  0.013030  0.024361  0.060081  0.072847\n",
       "ip  0.003193  0.019107  0.040064  0.080648  0.080585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
