{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# for some reason, need to go to the sheaf_kg directory in order for torch.load to work\n",
    "os.chdir('/home/gebhart/projects/sheaf_kg/sheaf_kg')\n",
    "\n",
    "import sheaf_kg.batch_harmonic_extension as harmonic_extension\n",
    "from sheaf_kg.sheafE_models import SheafE_Multisection, SheafE_Diag\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline\n",
    "from train_sheafE_betae import read_dataset, dataset_to_device, shuffle_datasets\n",
    "import cvxpy as cp \n",
    "import torch\n",
    "from cvxpylayers.torch import CvxpyLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FB15k-237'\n",
    "use_section = 0\n",
    "device = 'cpu'\n",
    "train_test_queries = 'test'\n",
    "model_name = 'SheafE_Complex_Queries_16embdim_16esdim_1sec_2norm_1epochs_SoftplusLoss_20210424-1401'\n",
    "save_loc = '/home/gebhart/projects/sheaf_kg/data/{}/{}/trained_model.pkl'.format(dataset,model_name)\n",
    "dataset_loc = '/home/gebhart/projects/sheaf_kg/data/{}-betae'.format(dataset)\n",
    "model = torch.load(save_loc, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxpy_problem(edge_index,dv,de,input_nodes):\n",
    "    nv = torch.max(torch.max(edge_index)).item() + 1\n",
    "    ne = edge_index.shape[1]\n",
    "    x = cp.Variable(nv*dv)\n",
    "    d = cp.Parameter((ne*de,nv*dv))\n",
    "    xB = cp.Parameter(len(input_nodes)*dv)\n",
    "    norm_constraints = [cp.norm(x[i*dv:(i+1)*dv]) <= 1 for i in range(nv) if i not in input_nodes]\n",
    "    boundary_constraints = [x[v*dv:(v+1)*dv] == xB[i*dv:(i+1)*dv] for (i,v) in enumerate(input_nodes)]\n",
    "    constraints = norm_constraints + boundary_constraints\n",
    "    objective = cp.Minimize(cp.norm(d @ x))\n",
    "    problem = cp.Problem(objective,constraints=constraints)\n",
    "\n",
    "    layer = CvxpyLayer(problem, parameters=[d,xB], variables=[x])\n",
    "\n",
    "    return layer\n",
    "\n",
    "def coboundary(edge_index,restriction_maps):\n",
    "    ne = edge_index.shape[1]\n",
    "    nv = torch.max(torch.max(edge_index)).item() + 1 #assume there are vertices indexed 0...max\n",
    "    de = restriction_maps.shape[2]\n",
    "    dv = restriction_maps.shape[3]   \n",
    "    d = torch.zeros((ne*de,nv*dv))\n",
    "    for e in range(ne):\n",
    "        h = edge_index[0,e]\n",
    "        t = edge_index[1,e]\n",
    "        d[e*de:(e+1)*de,h*dv:(h+1)*dv] = restriction_maps[e,0,:,:]\n",
    "        d[e*de:(e+1)*de,t*dv:(t+1)*dv] = -restriction_maps[e,1,:,:]\n",
    "    return d\n",
    "\n",
    "def linear_chain(ne):\n",
    "    edge_index = torch.zeros((2,ne),dtype=torch.int)\n",
    "    for e in range(ne):\n",
    "        edge_index[0,e] = e\n",
    "        edge_index[1,e] = e + 1\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = read_dataset(dataset_loc)\n",
    "datasets = dataset_to_device(shuffle_datasets(datasets), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_structures = ['2p', '3p']\n",
    "\n",
    "query_structures = [('e', ('r', 'r')), ('e', ('r', 'r', 'r')), (('e', ('r',)), ('e', ('r',))), (('e', ('r',)), ('e', ('r',)), ('e', ('r',))), (('e', ('r', 'r')), ('e', ('r',))), ((('e', ('r',)), ('e', ('r',))), ('r',))]\n",
    "\n",
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = pykeen.datasets.get_dataset(dataset=dataset, dataset_kwargs=dict(create_inverse_triples=False))\n",
    "# training = ds.training.mapped_triples\n",
    "# 237*8*16*8*16/training.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2p = cvxpy_problem(linear_chain(2), model.embedding_dim, model.edge_stalk_dim, [0])\n",
    "layer_3p = cvxpy_problem(linear_chain(3), model.embedding_dim, model.edge_stalk_dim, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_2p(model, entities, relations, targets, invs=None, sec=0):\n",
    "    all_ents = entities\n",
    "    all_rels = relations\n",
    "    all_invs = invs\n",
    "    n_path_ents = all_rels.shape[1]\n",
    "    num_queries = all_ents.shape[0]\n",
    "    \n",
    "    edge_indices = np.concatenate([np.arange(0,n_path_ents)[:,np.newaxis].T, np.arange(1,n_path_ents+1)[:,np.newaxis].T], axis=0)\n",
    "    edge_indices = torch.LongTensor(np.repeat(edge_indices[np.newaxis, :, :], num_queries, axis=0))\n",
    "\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, all_rels.flatten()).view(-1, all_rels.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, all_rels.flatten()).view(-1, all_rels.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "\n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    if all_invs is not None:\n",
    "        for ainvix in range(all_invs.shape[0]):\n",
    "            invs = all_invs[ainvix]\n",
    "            for invix in range(invs.shape[0]):\n",
    "                if invs[invix] == -1:\n",
    "                    tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                    restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                    restrictions[ainvix,invix,1,:,:] = tmp\n",
    "\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, all_ents)[:,:,sec]\n",
    "    target_embeddings = torch.index_select(model.ent_embeddings, 0, targets)[:,:,sec]\n",
    "    \n",
    "    d = harmonic_extension.coboundary(edge_indices, restrictions)\n",
    "    ret = torch.empty((num_queries, targets.shape[0]))\n",
    "    for qix in range(num_queries):\n",
    "        xopts, = layer_2p(d[qix], source_embeddings[qix].flatten())\n",
    "        r = xopts.reshape((-1,source_embeddings.shape[1]))\n",
    "        t = r[-1]\n",
    "        ret[qix,:] = torch.linalg.norm(t[None,:] - target_embeddings, ord=2, dim=1)\n",
    "#         ret[qix,:] = torch.matmul(target_embeddings, t)\n",
    "    return ret\n",
    "\n",
    "def L_3p(model, entities, relations, targets, invs=None, sec=0):\n",
    "    all_ents = entities\n",
    "    all_rels = relations\n",
    "    all_invs = invs\n",
    "    n_path_ents = all_rels.shape[1]\n",
    "    num_queries = all_ents.shape[0]\n",
    "    \n",
    "    edge_indices = np.concatenate([np.arange(0,n_path_ents)[:,np.newaxis].T, np.arange(1,n_path_ents+1)[:,np.newaxis].T], axis=0)\n",
    "    edge_indices = torch.LongTensor(np.repeat(edge_indices[np.newaxis, :, :], num_queries, axis=0))\n",
    "\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, all_rels.flatten()).view(-1, all_rels.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, all_rels.flatten()).view(-1, all_rels.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "\n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    if all_invs is not None:\n",
    "        for ainvix in range(all_invs.shape[0]):\n",
    "            invs = all_invs[ainvix]\n",
    "            for invix in range(invs.shape[0]):\n",
    "                if invs[invix] == -1:\n",
    "                    tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                    restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                    restrictions[ainvix,invix,1,:,:] = tmp\n",
    "\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, all_ents)[:,:,sec]\n",
    "    target_embeddings = torch.index_select(model.ent_embeddings, 0, targets)[:,:,sec]\n",
    "    \n",
    "    d = harmonic_extension.coboundary(edge_indices, restrictions)\n",
    "    ret = torch.empty((num_queries, targets.shape[0]))\n",
    "    for qix in range(num_queries):\n",
    "        xopts, = layer_3p(d[qix], source_embeddings[qix].flatten())\n",
    "        r = xopts.reshape((-1,source_embeddings.shape[1]))\n",
    "        t = r[-1]\n",
    "#         ret[qix,:] = torch.matmul(target_embeddings, t)\n",
    "        ret[qix,:] = torch.linalg.norm(t[None,:] - target_embeddings, ord=2, dim=1)\n",
    "    return ret\n",
    "\n",
    "query_name_fn_dict = {'2p': L_2p, '3p':L_3p}#, '2i': L_i, '3i':L_i, 'ip':L_ip, 'pi': L_pi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, model_inverses=False, sec=0, test_batch_size=5):\n",
    "    with torch.no_grad():\n",
    "        allhits1 = []\n",
    "        allhits3 = []\n",
    "        allhits5 = []\n",
    "        allhits10 = []\n",
    "        allmrr = []\n",
    "        query_names = []\n",
    "        for query_structure in test_query_structures:\n",
    "            print('Running query : {}'.format(query_structure))\n",
    "            hits1 = 0.\n",
    "            hits3 = 0.\n",
    "            hits5 = 0.\n",
    "            hits10 = 0.\n",
    "            mrr = 0.\n",
    "            cnt = 0\n",
    "            num_test = len(test_data[query_structure]['answers'])\n",
    "            for qix in tqdm(range(0, num_test//2, test_batch_size)):\n",
    "                if num_test - qix == 1:\n",
    "                    continue\n",
    "                entities = test_data[query_structure]['entities'][qix:qix+test_batch_size]\n",
    "                relations = test_data[query_structure]['relations'][qix:qix+test_batch_size]\n",
    "                if model_inverses:\n",
    "                    inverses = None\n",
    "                else:\n",
    "                    inverses = test_data[query_structure]['inverses'][qix:qix+test_batch_size]\n",
    "                all_answers = test_data[query_structure]['answers'][qix:qix+test_batch_size]\n",
    "                targets = torch.arange(model.num_entities)\n",
    "                Q = query_name_fn_dict[query_structure](model, entities, relations, targets, invs=inverses, sec=sec)\n",
    "#                 Q = Q[:,:,sec]\n",
    "                for i in range(Q.shape[0]):\n",
    "                    Qi = Q[i].squeeze()\n",
    "                    answers = all_answers[i]\n",
    "                    sortd,_ = torch.sort(Qi)\n",
    "                    idxleft = torch.searchsorted(sortd, Qi[answers], right=False) + 1\n",
    "                    idxright = torch.searchsorted(sortd, Qi[answers], right=True) + 1\n",
    "                    nl = idxleft.shape[0]\n",
    "                    nr = idxright.shape[0]\n",
    "                    # idxright = idxleft # throw this for optimistic ranking\n",
    "                    hits1 += ((torch.sum(idxleft <= 1)/nl + torch.sum(idxright <= 1)/nr) / 2.)\n",
    "                    hits3 += ((torch.sum(idxleft <= 3)/nl + torch.sum(idxright <= 3)/nr) / 2.)\n",
    "                    hits5 += ((torch.sum(idxleft <= 5)/nl + torch.sum(idxright <= 5)/nr) / 2.)\n",
    "                    hits10 += ((torch.sum(idxleft <= 10)/nl + torch.sum(idxright <= 10)/nr) / 2.)\n",
    "                    mrr += ((torch.sum(1./idxleft)/nl + torch.sum(1./idxright)/nr) / 2.)\n",
    "                    cnt += 1\n",
    "            if cnt > 0:\n",
    "                allhits1.append(hits1.item()/cnt)\n",
    "                allhits3.append(hits3.item()/cnt)\n",
    "                allhits5.append(hits5.item()/cnt)\n",
    "                allhits10.append(hits10.item()/cnt)\n",
    "                allmrr.append(mrr.item()/cnt)\n",
    "            else:\n",
    "                default = 0.\n",
    "                allhits1.append(default)\n",
    "                allhits3.append(default)\n",
    "                allhits5.append(default)\n",
    "                allhits10.append(default)\n",
    "                allmrr.append(default)\n",
    "\n",
    "        cols = ['hits@1', 'hits@3', 'hits@5', 'hits@10', 'mrr']\n",
    "        df = pd.DataFrame(np.array([allhits1, allhits3, allhits5, allhits10, allmrr]).T, columns=cols, index=test_query_structures)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/489 [00:00<?, ?it/s]/home/gebhart/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/diffcp/cone_program.py:282: UserWarning: Solved/Inaccurate.\n",
      "  warnings.warn(\"Solved/Inaccurate.\")\n",
      "  0%|          | 2/489 [00:00<00:34, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : 2p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:25<00:00, 19.31it/s]\n",
      "  0%|          | 1/487 [00:00<01:18,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : 3p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:36<00:00, 13.53it/s]\n"
     ]
    }
   ],
   "source": [
    "df = test(model, datasets['test-easy'], model_inverses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2p</th>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.144570</td>\n",
       "      <td>0.197666</td>\n",
       "      <td>0.298292</td>\n",
       "      <td>0.173938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3p</th>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.174237</td>\n",
       "      <td>0.250832</td>\n",
       "      <td>0.352918</td>\n",
       "      <td>0.205781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@1    hits@3    hits@5   hits@10       mrr\n",
       "2p  0.028667  0.144570  0.197666  0.298292  0.173938\n",
       "3p  0.049520  0.174237  0.250832  0.352918  0.205781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
