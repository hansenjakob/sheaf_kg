{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# for some reason, need to go to the sheaf_kg directory in order for torch.load to work\n",
    "os.chdir('/home/gebhart/projects/sheaf_kg/sheaf_kg')\n",
    "\n",
    "import sheaf_kg.batch_harmonic_extension as harmonic_extension\n",
    "from sheaf_kg.sheafE_models import SheafE_Multisection, SheafE_Diag\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FB15k-237'\n",
    "num_test = 3000\n",
    "num_train = 2000\n",
    "batch_size = 50\n",
    "use_section = 0\n",
    "model_name = 'SheafE_Multisection_64embdim_64esdim_1sec_1norm_1000epochs_SoftplusLossloss_20210304-1923'\n",
    "save_loc = '/home/gebhart/projects/sheaf_kg/data/{}/{}/trained_model.pkl'.format(dataset,model_name)\n",
    "betae_path = '/home/gebhart/projects/sheaf_kg/data/{}-betae'.format(dataset)\n",
    "model = torch.load(save_loc).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_structures = [('e',('r',)), ('e', ('r', 'r')), ('e', ('r', 'r', 'r')), (('e', ('r',)), ('e', ('r',))), (('e', ('r',)), ('e', ('r',)), ('e', ('r',))), (('e', ('r', 'r')), ('e', ('r',))), ((('e', ('r',)), ('e', ('r',))), ('r',))]\n",
    "\n",
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're trying to map triples with 30 entities and 0 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "In total 28 from 20466 triples were filtered out\n"
     ]
    }
   ],
   "source": [
    "# ds = pykeen.datasets.get_dataset(dataset=dataset)\n",
    "ds = pykeen.datasets.get_dataset(dataset=dataset, dataset_kwargs=dict(create_inverse_triples=False))\n",
    "training = ds.training.mapped_triples\n",
    "relid2label = ds.training.relation_id_to_label \n",
    "label2relid = {v:k for k,v in relid2label.items()}\n",
    "\n",
    "entid2label = ds.training.entity_id_to_label \n",
    "label2entid = {v:k for k,v in entid2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(betae_path,'test-queries.pkl'), 'rb') as f:\n",
    "    test_queries = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(betae_path,'test-easy-answers.pkl'), 'rb') as f:\n",
    "    test_answers = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(betae_path,'train-queries.pkl'), 'rb') as f:\n",
    "    train_queries = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(betae_path,'train-answers.pkl'), 'rb') as f:\n",
    "    train_answers = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(betae_path,'id2rel.pkl'), 'rb') as f:\n",
    "    id2rel = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(betae_path,'id2ent.pkl'), 'rb') as f:\n",
    "    id2ent = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ent(e):\n",
    "    return label2entid[id2ent[e]]\n",
    "\n",
    "def map_rel(r):\n",
    "    relname = id2rel[r]\n",
    "    return label2relid[relname[1:]]\n",
    "\n",
    "def orient_rel(r):\n",
    "    orientation = 1\n",
    "    relname = id2rel[r]\n",
    "    if relname[0] == '-':\n",
    "        orientation = -1\n",
    "    return orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_p(queries, model, targets):\n",
    "    '''query of form ('e', ('r', 'r', ... , 'r')).\n",
    "    here we assume 2 or more relations are present so 2p or greater\n",
    "    '''\n",
    "    all_ents = [map_ent(query[0]) for query in queries]\n",
    "    all_rels = [[map_rel(r) for r in query[1]] for query in queries]\n",
    "    all_invs = [[orient_rel(r) for r in query[1]] for query in queries]\n",
    "    n_path_ents = len(all_rels[0])\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    edge_indices = np.concatenate([np.arange(0,n_path_ents)[:,np.newaxis].T, np.arange(1,n_path_ents+1)[:,np.newaxis].T], axis=0)\n",
    "    edge_indices = torch.LongTensor(np.repeat(edge_indices[np.newaxis, :, :], num_queries, axis=0))\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(all_rels)\n",
    "    \n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    for ainvix in range(len(all_invs)):\n",
    "        invs = all_invs[ainvix]\n",
    "        for invix in range(len(invs)):\n",
    "            if invs[invix] == -1:\n",
    "                tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                restrictions[ainvix,invix,1,:,:] = tmp\n",
    "\n",
    "    ent_idx_tensor = torch.LongTensor(all_ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor).view(-1, model.embedding_dim, model.num_sections)\n",
    "    \n",
    "    B = torch.LongTensor(np.repeat(np.array([0,n_path_ents],np.int)[np.newaxis,:], num_queries, axis=0))\n",
    "    U = torch.LongTensor(np.repeat(np.array(range(1,n_path_ents),np.int)[np.newaxis,:], num_queries, axis=0))\n",
    "    source_vertices = np.zeros((num_queries,1), dtype=np.int)\n",
    "    target_vertices = np.full((num_queries,1), 1, dtype=np.int)\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    target_embeddings = torch.mean(torch.index_select(model.ent_embeddings, 0, targets), -1)\n",
    "    Q = harmonic_extension.compute_costs(LSchur,source_vertices,target_vertices,torch.mean(source_embeddings, -1).view(batch_size, -1),target_embeddings,source_embeddings.shape[1])\n",
    "    return Q\n",
    "\n",
    "# def L_i(queries, model, targets):\n",
    "#     '''query of form (('e', ('r',)), ('e', ('r',)), ... , ('e', ('r',)))'''\n",
    "#     num_intersects = len(queries[0])\n",
    "#     all_ents = [[map_ent(pair[0]) for pair in query] for query in queries]\n",
    "#     all_rels = [[map_rel(pair[1][0]) for pair in query] for query in queries]\n",
    "#     all_invs = [[orient_rel(pair[1][0]) for pair in query] for query in queries]\n",
    "#     n_ents = len(all_ents[0])\n",
    "#     num_queries = len(queries)\n",
    "    \n",
    "#     rel_idx_tensor = torch.LongTensor(all_rels)\n",
    "#     left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "#     right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "#     restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "#     for ainvix in range(len(all_invs)):\n",
    "#         invs = all_invs[ainvix]\n",
    "#         for invix in range(len(invs)):\n",
    "#             if invs[invix] == -1:\n",
    "#                 tmp = restrictions[ainvix,invix,1,:,:].copy()\n",
    "#                 restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "#                 restrictions[ainvix,invix,1,:,:] = tmp\n",
    "                \n",
    "#     left_restrictions = restrictions[:,:,0,:,:].view(-1, model.edge_stalk_dim, model.embedding_dim)\n",
    "#     right_restrictions = restrictions[:,:,1,:,:].view(-1, 1, model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "#     ent_idx_tensor = torch.LongTensor(all_ents)\n",
    "#     source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor.flatten()).view(-1, model.embedding_dim, model.num_sections)\n",
    "#     target_embeddings = torch.mean(torch.index_select(model.ent_embeddings, 0, targets), -1).view(1, -1, model.embedding_dim, 1)\n",
    "#     proj_h = left_restrictions @ source_embeddings\n",
    "#     proj_t = right_restrictions @ target_embeddings\n",
    "\n",
    "#     Q = torch.norm(proj_h[:, None, :, :] - proj_t[:, :, :, :], dim=(-1,-2), p=model.scoring_fct_norm)**2\n",
    "#     return Q\n",
    "\n",
    "\n",
    "def L_i(queries, model, targets):\n",
    "    '''query of form (('e', ('r',)), ('e', ('r',)), ... , ('e', ('r',)))'''\n",
    "    num_intersects = len(queries[0])\n",
    "    all_ents = [[map_ent(pair[0]) for pair in query] for query in queries]\n",
    "    all_rels = [[map_rel(pair[1][0]) for pair in query] for query in queries]\n",
    "    all_invs = [[orient_rel(pair[1][0]) for pair in query] for query in queries]\n",
    "    n_ents = len(all_ents[0])\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    edge_indices = np.concatenate([np.full(n_ents,n_ents)[:,np.newaxis].T, np.arange(0,n_ents)[:,np.newaxis].T], axis=0)\n",
    "    edge_indices = torch.LongTensor(np.repeat(edge_indices[np.newaxis, :, :], num_queries, axis=0))\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(all_rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    for ainvix in range(len(all_invs)):\n",
    "        invs = all_invs[ainvix]\n",
    "        for invix in range(len(invs)):\n",
    "            if invs[invix] == -1:\n",
    "                tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                restrictions[ainvix,invix,1,:,:] = tmp\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(all_ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor.flatten()).view(-1, model.embedding_dim, model.num_sections)\n",
    "        \n",
    "    L = harmonic_extension.Laplacian(edge_indices, restrictions)\n",
    "    source_vertices = np.repeat(np.arange(n_ents)[np.newaxis,:], num_queries, axis=0)\n",
    "    target_vertices = np.full((num_queries, 1),n_ents, dtype=np.int)\n",
    "    target_embeddings = torch.mean(torch.index_select(model.ent_embeddings, 0, targets), -1)\n",
    "    Q = harmonic_extension.compute_costs(L,source_vertices,target_vertices,torch.mean(source_embeddings, -1).view(batch_size, -1),target_embeddings,source_embeddings.shape[1])\n",
    "    return Q\n",
    "\n",
    "\n",
    "def L_ip(queries, model, targets):\n",
    "    '''query of form ((('e', ('r',)), ('e', ('r',))), ('r',))'''\n",
    "    all_ents = [[map_ent(t[0]) for t in query[0]] for query in queries] \n",
    "    all_rels = [[map_rel(query[0][0][1][0]), map_rel(query[0][1][1][0]), map_rel(query[1][0])] for query in queries]\n",
    "    all_invs = [[orient_rel(query[0][0][1][0]), orient_rel(query[0][1][1][0]), orient_rel(query[1][0])] for query in queries]\n",
    "    n_ents = len(all_ents[0])\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    edge_indices = torch.LongTensor(np.repeat(np.array([[0,2],[1,2],[2,3]],np.int).T[np.newaxis,:,:], num_queries, axis=0))\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(all_rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    for ainvix in range(len(all_invs)):\n",
    "        invs = all_invs[ainvix]\n",
    "        for invix in range(len(invs)):\n",
    "            if invs[invix] == -1:\n",
    "                tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                restrictions[ainvix,invix,1,:,:] = tmp\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(all_ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor.flatten()).view(-1, model.embedding_dim, model.num_sections)\n",
    "    \n",
    "    B = torch.LongTensor(np.repeat(np.array([0,2,3],dtype=np.int)[np.newaxis,:], num_queries, axis=0))\n",
    "    U = torch.LongTensor(np.full((num_queries,1), 1, dtype=np.int))\n",
    "    source_vertices = np.repeat(np.array([0,1], dtype=np.int)[np.newaxis,:], num_queries, axis=0)\n",
    "    target_vertices = np.full((num_queries,1), 2, dtype=np.int)\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    target_embeddings = torch.mean(torch.index_select(model.ent_embeddings, 0, targets), -1)\n",
    "    Q = harmonic_extension.compute_costs(LSchur,source_vertices,target_vertices,torch.mean(source_embeddings, -1).view(batch_size, -1),target_embeddings,source_embeddings.shape[1])\n",
    "    return Q\n",
    "\n",
    "def L_pi(queries, model, targets):\n",
    "    '''query of form (('e', ('r', 'r')), ('e', ('r',)))'''\n",
    "    all_ents = [[map_ent(t[0]) for t in query] for query in queries]\n",
    "    all_rels = [[map_rel(query[0][1][0]), map_rel(query[0][1][1]), map_rel(query[1][1][0])] for query in queries]\n",
    "    all_invs = [[orient_rel(query[0][1][0]), orient_rel(query[0][1][1]), orient_rel(query[1][1][0])] for query in queries]\n",
    "    n_ents = len(all_ents[0])\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    edge_indices = torch.LongTensor(np.repeat(np.array([[0,2],[2,3],[1,3]],np.int).T[np.newaxis,:,:], num_queries, axis=0))\n",
    "    \n",
    "    rel_idx_tensor = torch.LongTensor(all_rels)\n",
    "    left_restrictions = torch.index_select(model.left_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    right_restrictions = torch.index_select(model.right_embeddings, 0, rel_idx_tensor.flatten()).view(-1,rel_idx_tensor.shape[1], model.edge_stalk_dim, model.embedding_dim)\n",
    "    \n",
    "    restrictions = torch.cat((left_restrictions.unsqueeze(2), right_restrictions.unsqueeze(2)), dim=2)\n",
    "    for ainvix in range(len(all_invs)):\n",
    "        invs = all_invs[ainvix]\n",
    "        for invix in range(len(invs)):\n",
    "            if invs[invix] == -1:\n",
    "                tmp = torch.clone(restrictions[ainvix,invix,0,:,:])\n",
    "                restrictions[ainvix,invix,0,:,:] = restrictions[ainvix,invix,1,:,:]\n",
    "                restrictions[ainvix,invix,1,:,:] = tmp\n",
    "    \n",
    "    ent_idx_tensor = torch.LongTensor(all_ents)\n",
    "    source_embeddings = torch.index_select(model.ent_embeddings, 0, ent_idx_tensor.flatten()).view(-1, model.embedding_dim, model.num_sections)\n",
    "    \n",
    "    B = torch.LongTensor(np.repeat(np.array([0,1,3], dtype=np.int)[np.newaxis, :], num_queries, axis=0))\n",
    "    U = torch.LongTensor(np.full((num_queries, 1), 2, dtype=np.int))\n",
    "    source_vertices = np.repeat(np.array([0,1], dtype=np.int).T[np.newaxis,:], num_queries, axis=0)\n",
    "    target_vertices = np.full((num_queries,1), 2, dtype=np.int)\n",
    "    LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "    target_embeddings = torch.mean(torch.index_select(model.ent_embeddings, 0, targets), -1)\n",
    "    Q = harmonic_extension.compute_costs(LSchur,source_vertices,target_vertices,torch.mean(source_embeddings, -1).view(batch_size, -1),target_embeddings,source_embeddings.shape[1])\n",
    "    return Q\n",
    "\n",
    "\n",
    "query_name_fn_dict = {'1p':L_p, '2p':L_p, '3p':L_p, '2i':L_i, '3i':L_i, 'ip':L_ip, 'pi':L_pi}\n",
    "\n",
    "def softplusloss(logits, labels):\n",
    "    loss_fn = torch.nn.Softplus(beta=1, threshold=20)\n",
    "    assert 0. <= labels.min() and labels.max() <= 1.\n",
    "    # scale labels from [0, 1] to [-1, 1]\n",
    "    labels = 2 * labels - 1\n",
    "    loss = loss_fn((-1) * labels * logits)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, query_type, batch_queries, batch_targets, batch_answers):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    fn = query_name_fn_dict[query_name]\n",
    "    \n",
    "    Q = fn(qs, model, batch_targets)\n",
    "    loss = softplusloss(Q,batch_answers)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:15<00:00,  3.90it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:28<00:00,  2.07it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:31<00:00,  1.88it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:28<00:00,  2.10it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:28<00:00,  2.10it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r', 'r')), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:30<00:00,  1.98it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ((('e', ('r',)), ('e', ('r',))), ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 23s, sys: 1min 43s, total: 11min 7s\n",
      "Wall time: 3min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allhits1 = []\n",
    "allhits3 = []\n",
    "allhits5 = []\n",
    "allhits10 = []\n",
    "allmrr = []\n",
    "query_names = []\n",
    "# target_embeddings = model.ent_embeddings.view(-1, model.embedding_dim, model.num_sections)[:,:,use_section].T\n",
    "target_embeddings = torch.mean(model.ent_embeddings.view(-1, model.embedding_dim, model.num_sections), -1)\n",
    "for query_structure in query_structures:\n",
    "    print('Running query : {}'.format(query_structure))\n",
    "    query_name = query_name_dict[query_structure]\n",
    "    query_names.append(query_name)\n",
    "    fn = query_name_fn_dict[query_name]\n",
    "    hits1 = 0.\n",
    "    hits3 = 0.\n",
    "    hits5 = 0.\n",
    "    hits10 = 0.\n",
    "    mrr = 0.\n",
    "    cnt = 0\n",
    "    # the len() > 0 part is to determine whether we have an \"easy\" query\n",
    "    queries = [q for q in test_queries[query_structure] if len(test_answers[q]) > 0] \n",
    "    for qix in tqdm(range(0, num_test, batch_size)):\n",
    "        qs = queries[qix:qix+batch_size]\n",
    "        # we have a non-trivial \"easy\" query\n",
    "        if len(qs) > 0:\n",
    "            all_answers = [[map_ent(a) for a in test_answers[query]] for query in qs]\n",
    "            Q = fn(qs, model, torch.arange(model.ent_embeddings.shape[0]))\n",
    "            for i in range(len(qs)):\n",
    "                Qi = Q[i].squeeze()\n",
    "                answers = all_answers[i]\n",
    "                sortd,_ = torch.sort(Qi)\n",
    "                idxleft = torch.searchsorted(sortd, Qi[answers], right=False) + 1\n",
    "                idxright = torch.searchsorted(sortd, Qi[answers], right=True) + 1\n",
    "                nl = idxleft.shape[0]\n",
    "                nr = idxright.shape[0]\n",
    "                # idxright = idxleft # throw this for optimistic ranking\n",
    "                hits1 += ((torch.sum(idxleft <= 1)/nl + torch.sum(idxright <= 1)/nr) / 2.)\n",
    "                hits3 += ((torch.sum(idxleft <= 3)/nl + torch.sum(idxright <= 3)/nr) / 2.)\n",
    "                hits5 += ((torch.sum(idxleft <= 5)/nl + torch.sum(idxright <= 5)/nr) / 2.)\n",
    "                hits10 += ((torch.sum(idxleft <= 10)/nl + torch.sum(idxright <= 10)/nr) / 2.)\n",
    "                mrr += ((torch.sum(1./idxleft)/nl + torch.sum(1./idxright)/nr) / 2.)\n",
    "                cnt += 1\n",
    "    if cnt > 0:\n",
    "        allhits1.append(hits1/cnt)\n",
    "        allhits3.append(hits3/cnt)\n",
    "        allhits5.append(hits5/cnt)\n",
    "        allhits10.append(hits10/cnt)\n",
    "        allmrr.append(mrr/cnt)\n",
    "    else:\n",
    "        default = 0.\n",
    "        allhits1.append(default)\n",
    "        allhits3.append(default)\n",
    "        allhits5.append(default)\n",
    "        allhits10.append(default)\n",
    "        allmrr.append(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1p</th>\n",
       "      <td>0.890658</td>\n",
       "      <td>3.978050</td>\n",
       "      <td>6.833235</td>\n",
       "      <td>12.364747</td>\n",
       "      <td>4.872074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2p</th>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.108042</td>\n",
       "      <td>0.231208</td>\n",
       "      <td>0.602859</td>\n",
       "      <td>0.341228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3p</th>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>0.215841</td>\n",
       "      <td>0.199437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2i</th>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.052336</td>\n",
       "      <td>0.095780</td>\n",
       "      <td>0.091612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3i</th>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.026365</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.156972</td>\n",
       "      <td>0.099178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pi</th>\n",
       "      <td>0.026343</td>\n",
       "      <td>0.264002</td>\n",
       "      <td>0.536224</td>\n",
       "      <td>1.207865</td>\n",
       "      <td>0.703811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.076380</td>\n",
       "      <td>0.353962</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>1.304240</td>\n",
       "      <td>0.792076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@1    hits@3    hits@5    hits@10       mrr\n",
       "1p  0.890658  3.978050  6.833235  12.364747  4.872074\n",
       "2p  0.015674  0.108042  0.231208   0.602859  0.341228\n",
       "3p  0.006287  0.035261  0.106931   0.215841  0.199437\n",
       "2i  0.004018  0.024717  0.052336   0.095780  0.091612\n",
       "3i  0.009850  0.026365  0.066667   0.156972  0.099178\n",
       "pi  0.026343  0.264002  0.536224   1.207865  0.703811\n",
       "ip  0.076380  0.353962  0.600962   1.304240  0.792076"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hits@1', 'hits@3', 'hits@5', 'hits@10', 'mrr']\n",
    "df_before = pd.DataFrame(np.array([allhits1, allhits3, allhits5, allhits10, allmrr]).T, columns=cols, index=query_names) \n",
    "df_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:07<00:00,  5.71it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:16<00:00,  2.43it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:39<00:00,  1.02it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:18<00:00,  2.13it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "100%|██████████| 40/40 [00:00<00:00, 180400.17it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 196915.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r', 'r')), ('e', ('r',)))\n",
      "Running query : ((('e', ('r',)), ('e', ('r',))), ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_names = []\n",
    "for query_structure in query_structures:\n",
    "    print('Running query : {}'.format(query_structure))\n",
    "    query_name = query_name_dict[query_structure]\n",
    "    query_names.append(query_name)\n",
    "\n",
    "    # the len() > 0 part is to determine whether we have an \"easy\" query\n",
    "    queries = [q for q in train_queries[query_structure] if len(train_answers[q]) > 0]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=1e-4\n",
    "        )\n",
    "    \n",
    "    for qix in tqdm(range(0, num_train, batch_size)):\n",
    "        qs = queries[qix:qix+batch_size]\n",
    "        # we have a non-trivial \"easy\" query\n",
    "        if len(qs) > 0:\n",
    "            true_targets = torch.LongTensor([np.random.choice([map_ent(a) for a in train_answers[query]]) for query in qs])\n",
    "            true_answers = torch.ones(true_targets.shape)\n",
    "            neg_targets = torch.randint(model.num_entities, true_targets.shape)\n",
    "            neg_answers = torch.zeros(neg_targets.shape)\n",
    "            \n",
    "            true_loss = train_step(model, optimizer, query_name, qs, true_targets, true_answers)\n",
    "            neg_loss = train_step(model, optimizer, query_name, qs, neg_targets, neg_answers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:26<00:00,  2.24it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.05it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ('e', ('r', 'r', 'r'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:31<00:00,  1.88it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:26<00:00,  2.28it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r',)), ('e', ('r',)), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.05it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : (('e', ('r', 'r')), ('e', ('r',)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:30<00:00,  2.00it/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query : ((('e', ('r',)), ('e', ('r',))), ('r',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 48s, sys: 1min 49s, total: 11min 37s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allhits1 = []\n",
    "allhits3 = []\n",
    "allhits5 = []\n",
    "allhits10 = []\n",
    "allmrr = []\n",
    "query_names = []\n",
    "model.eval()\n",
    "target_embeddings = torch.mean(model.ent_embeddings.view(-1, model.embedding_dim, model.num_sections), -1)\n",
    "for query_structure in query_structures:\n",
    "    print('Running query : {}'.format(query_structure))\n",
    "    query_name = query_name_dict[query_structure]\n",
    "    query_names.append(query_name)\n",
    "    fn = query_name_fn_dict[query_name]\n",
    "    hits1 = 0.\n",
    "    hits3 = 0.\n",
    "    hits5 = 0.\n",
    "    hits10 = 0.\n",
    "    mrr = 0.\n",
    "    cnt = 0\n",
    "    # the len() > 0 part is to determine whether we have an \"easy\" query\n",
    "    queries = [q for q in test_queries[query_structure] if len(test_answers[q]) > 0] \n",
    "    for qix in tqdm(range(0, num_test, batch_size)):\n",
    "        qs = queries[qix:qix+batch_size]\n",
    "        # we have a non-trivial \"easy\" query\n",
    "        if len(qs) > 0:\n",
    "            all_answers = [[map_ent(a) for a in test_answers[query]] for query in qs]\n",
    "            Q = fn(qs, model, torch.arange(model.num_entities))\n",
    "            for i in range(len(qs)):\n",
    "                Qi = Q[i].squeeze()\n",
    "                answers = all_answers[i]\n",
    "                sortd,_ = torch.sort(Qi)\n",
    "                idxleft = torch.searchsorted(sortd, Qi[answers], right=False) + 1\n",
    "                idxright = torch.searchsorted(sortd, Qi[answers], right=True) + 1\n",
    "                nl = idxleft.shape[0]\n",
    "                nr = idxright.shape[0]\n",
    "                # idxright = idxleft # throw this for optimistic ranking\n",
    "                hits1 += ((torch.sum(idxleft <= 1)/nl + torch.sum(idxright <= 1)/nr) / 2.)\n",
    "                hits3 += ((torch.sum(idxleft <= 3)/nl + torch.sum(idxright <= 3)/nr) / 2.)\n",
    "                hits5 += ((torch.sum(idxleft <= 5)/nl + torch.sum(idxright <= 5)/nr) / 2.)\n",
    "                hits10 += ((torch.sum(idxleft <= 10)/nl + torch.sum(idxright <= 10)/nr) / 2.)\n",
    "                mrr += ((torch.sum(1./idxleft)/nl + torch.sum(1./idxright)/nr) / 2.)\n",
    "                cnt += 1\n",
    "    if cnt > 0:\n",
    "        allhits1.append(hits1/cnt)\n",
    "        allhits3.append(hits3/cnt)\n",
    "        allhits5.append(hits5/cnt)\n",
    "        allhits10.append(hits10/cnt)\n",
    "        allmrr.append(mrr/cnt)\n",
    "    else:\n",
    "        default = 0.\n",
    "        allhits1.append(default)\n",
    "        allhits3.append(default)\n",
    "        allhits5.append(default)\n",
    "        allhits10.append(default)\n",
    "        allmrr.append(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1p</th>\n",
       "      <td>0.168014</td>\n",
       "      <td>1.642308</td>\n",
       "      <td>3.120205</td>\n",
       "      <td>5.625039</td>\n",
       "      <td>2.510458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2p</th>\n",
       "      <td>0.138404</td>\n",
       "      <td>0.724345</td>\n",
       "      <td>1.349209</td>\n",
       "      <td>2.839929</td>\n",
       "      <td>1.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3p</th>\n",
       "      <td>0.119782</td>\n",
       "      <td>0.618986</td>\n",
       "      <td>1.180071</td>\n",
       "      <td>2.507257</td>\n",
       "      <td>1.260078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2i</th>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>0.097960</td>\n",
       "      <td>0.090910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3i</th>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.044234</td>\n",
       "      <td>0.058088</td>\n",
       "      <td>0.157711</td>\n",
       "      <td>0.103162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pi</th>\n",
       "      <td>0.088353</td>\n",
       "      <td>0.617174</td>\n",
       "      <td>1.330234</td>\n",
       "      <td>2.728086</td>\n",
       "      <td>1.274468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.082939</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>1.606033</td>\n",
       "      <td>0.863820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@1    hits@3    hits@5   hits@10       mrr\n",
       "1p  0.168014  1.642308  3.120205  5.625039  2.510458\n",
       "2p  0.138404  0.724345  1.349209  2.839929  1.410335\n",
       "3p  0.119782  0.618986  1.180071  2.507257  1.260078\n",
       "2i  0.001240  0.036673  0.047739  0.097960  0.090910\n",
       "3i  0.009850  0.044234  0.058088  0.157711  0.103162\n",
       "pi  0.088353  0.617174  1.330234  2.728086  1.274468\n",
       "ip  0.082939  0.393035  0.780401  1.606033  0.863820"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hits@1', 'hits@3', 'hits@5', 'hits@10', 'mrr']\n",
    "df_after = pd.DataFrame(np.array([allhits1, allhits3, allhits5, allhits10, allmrr]).T, columns=cols, index=query_names) \n",
    "df_after * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1p</th>\n",
       "      <td>-0.722644</td>\n",
       "      <td>-2.335742</td>\n",
       "      <td>-3.713030</td>\n",
       "      <td>-6.739708</td>\n",
       "      <td>-2.361616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2p</th>\n",
       "      <td>0.122730</td>\n",
       "      <td>0.616303</td>\n",
       "      <td>1.118001</td>\n",
       "      <td>2.237070</td>\n",
       "      <td>1.069108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3p</th>\n",
       "      <td>0.113494</td>\n",
       "      <td>0.583726</td>\n",
       "      <td>1.073141</td>\n",
       "      <td>2.291416</td>\n",
       "      <td>1.060640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2i</th>\n",
       "      <td>-0.002778</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>-0.004598</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>-0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3i</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>-0.008579</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pi</th>\n",
       "      <td>0.062009</td>\n",
       "      <td>0.353171</td>\n",
       "      <td>0.794009</td>\n",
       "      <td>1.520221</td>\n",
       "      <td>0.570657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.039073</td>\n",
       "      <td>0.179438</td>\n",
       "      <td>0.301793</td>\n",
       "      <td>0.071744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@1    hits@3    hits@5   hits@10       mrr\n",
       "1p -0.722644 -2.335742 -3.713030 -6.739708 -2.361616\n",
       "2p  0.122730  0.616303  1.118001  2.237070  1.069108\n",
       "3p  0.113494  0.583726  1.073141  2.291416  1.060640\n",
       "2i -0.002778  0.011956 -0.004598  0.002180 -0.000702\n",
       "3i  0.000000  0.017868 -0.008579  0.000740  0.003984\n",
       "pi  0.062009  0.353171  0.794009  1.520221  0.570657\n",
       "ip  0.006559  0.039073  0.179438  0.301793  0.071744"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_after - df_before) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
