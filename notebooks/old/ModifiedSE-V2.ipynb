{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Nations'\n",
    "num_epochs = 10\n",
    "embedding_dim = 50\n",
    "lbda = 0.9\n",
    "loss = 'MarginRankingLoss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.LongTensor([[0, 1, 1],\n",
    "                          [2, 0, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "t = torch.sparse.FloatTensor(i, v, torch.Size([2,3]))._indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(torch.index_select(t, 0, torch.LongTensor([0,1])), 1, torch.LongTensor([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "from typing import Optional\n",
    "\n",
    "from pykeen.models import StructuredEmbedding\n",
    "from pykeen.models.base import EntityEmbeddingModel\n",
    "from pykeen.nn import Embedding\n",
    "from pykeen.losses import Loss\n",
    "from pykeen.nn.init import xavier_uniform_\n",
    "from pykeen.regularizers import Regularizer\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.typing import DeviceHint\n",
    "from pykeen.utils import compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedSE(EntityEmbeddingModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        triples_factory,\n",
    "        node_stalk_dims = [],\n",
    "        edge_stalk_dims = [],\n",
    "        scoring_fct_norm = 1,\n",
    "        loss = None,\n",
    "        preferred_device = None,\n",
    "        random_seed = None,\n",
    "        regularizer = None\n",
    "    ):\n",
    "        r\"\"\"Initialize SE.\n",
    "\n",
    "        :param embedding_dim: The entity embedding dimension $d$. Is usually $d \\in [50, 300]$.\n",
    "        :param scoring_fct_norm: The $l_p$ norm. Usually 1 for SE.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            triples_factory=triples_factory,\n",
    "            loss=loss,\n",
    "            preferred_device=preferred_device,\n",
    "            random_seed=random_seed,\n",
    "            regularizer=regularizer\n",
    "        )\n",
    "        \n",
    "        if len(node_stalk_dims) == 0:\n",
    "            self.node_stalk_dims = [10 for i in range(self.triples_factory.num_entities)]\n",
    "        if len(edge_stalk_dims) == 0:\n",
    "            self.edge_stalk_dims = [10 for i in range(self.triples_factory.num_relations)]\n",
    "        \n",
    "        self.scoring_fct_norm = scoring_fct_norm\n",
    "        \n",
    "        self.node_stalk_dims = torch.LongTensor(self.node_stalk_dims)\n",
    "        self.edge_stalk_dims = torch.LongTensor(self.edge_stalk_dims)\n",
    "        nrows = self.node_stalk_dims.sum().item()\n",
    "        ncols = self.edge_stalk_dims.sum().item()\n",
    "        \n",
    "        self.node_start_idx = torch.cat((torch.zeros(1), torch.cumsum(self.node_stalk_dims, 0)), 0).long()\n",
    "        self.edge_start_idx = torch.cat((torch.zeros(1), torch.cumsum(self.edge_stalk_dims, 0)), 0).long()\n",
    "        \n",
    "        self.entity_embeddings2 = [torch.nn.init.normal_(torch.empty(self.node_stalk_dims[i], requires_grad=True)) for i in range(len(self.node_stalk_dims))]\n",
    "        \n",
    "        rc_idxs = []\n",
    "        data = []\n",
    "        \n",
    "        self.entity_idxs = [[] for i in range(self.node_stalk_dims.shape[0])]\n",
    "        self.relation_idxs = [[] for i in range(self.edge_stalk_dims.shape[0])]\n",
    "        \n",
    "        for triple in self.triples_factory.mapped_triples:\n",
    "            e1_idx = triple[0]\n",
    "            r_idx = triple[1]\n",
    "            e2_idx = triple[2]\n",
    "            \n",
    "            e1_start = self.node_start_idx[e1_idx].item()\n",
    "            e1_end = self.node_start_idx[e1_idx+1].item()\n",
    "            r_start = self.edge_start_idx[r_idx].item()\n",
    "            r_end = self.edge_start_idx[r_idx+1].item()\n",
    "            e2_start = self.node_start_idx[e2_idx].item()\n",
    "            e2_end = self.node_start_idx[e2_idx+1].item()\n",
    "            \n",
    "            r1_init = torch.nn.init.normal_(torch.empty(self.node_stalk_dims[e1_idx]*self.edge_stalk_dims[r_idx]))\n",
    "            r2_init = torch.nn.init.normal_(torch.empty(self.node_stalk_dims[e2_idx]*self.edge_stalk_dims[r_idx]))\n",
    "            \n",
    "            self.entity_idxs[e1_idx] = list(range(e1_start,e1_end))\n",
    "            self.entity_idxs[e2_idx] = list(range(e2_start,e2_end))\n",
    "            self.relation_idxs[r_idx] = list(range(r_start,r_end))\n",
    "            \n",
    "            rc_idxs += list(itertools.product(self.entity_idxs[e1_idx], self.relation_idxs[r_idx]))\n",
    "            data.append(r1_init)\n",
    "            rc_idxs += list(itertools.product(self.entity_idxs[e2_idx], self.relation_idxs[r_idx]))\n",
    "            data.append(-r2_init)\n",
    "        \n",
    "        i = torch.LongTensor(rc_idxs)\n",
    "        v = torch.cat(data, dim=0)\n",
    "        self.B = torch.sparse_coo_tensor(i.t(), v, torch.Size([nrows,ncols]))\n",
    "        self.B = self.B.to(self.device)\n",
    "\n",
    "    def _reset_parameters_(self):  # noqa: D102\n",
    "        super()._reset_parameters_()\n",
    "\n",
    "    def score_hrt(self, hrt_batch: torch.LongTensor) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        unqh = torch.unique(hrt_batch[:,0])\n",
    "        unqt = torch.unique(hrt_batch[:,2])\n",
    "        unqr = torch.unique(hrt_batch[:,1])\n",
    "        \n",
    "        xh = [self.entity_embeddings2[i] for i in unqh]\n",
    "        xt = [self.entity_embeddings2[i] for i in unqt]\n",
    "        xv = torch.cat(xh + xt, dim=0)\n",
    "        \n",
    "        n_rows = (self.node_stalk_dims[unqh].sum() + self.node_stalk_dims[unqt].sum()).item()\n",
    "        n_cols = self.edge_stalk_dims[unqr].sum().item()\n",
    "        \n",
    "        h_idxs = []\n",
    "        for eidx in unqh:\n",
    "            h_idxs += self.entity_idxs[eidx]\n",
    "        t_idxs = []\n",
    "        for eidx in unqt:\n",
    "            t_idxs += self.entity_idxs[eidx]\n",
    "        r_idxs = []\n",
    "        for ridx in unqr:\n",
    "            r_idxs += self.relation_idxs[ridx]\n",
    "        row_idxs = torch.LongTensor(h_idxs + t_idxs)\n",
    "        col_idxs = torch.LongTensor(r_idxs)\n",
    "        B = torch.index_select(torch.index_select(self.B, 0, row_idxs), 1, col_idxs)\n",
    "        print(B.shape)\n",
    "        L = B @ B.T\n",
    "        Lv = xv.T @ L @ xv\n",
    "        \n",
    "        return -Lv\n",
    "\n",
    "    def score_t(self, hr_batch: torch.LongTensor, slice_size: int = None) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        h = self.entity_embeddings(indices=hr_batch[:, 0]).view(-1, self.embedding_dim, 1)\n",
    "        rel_h = self.left_relation_embeddings(indices=hr_batch[:, 1]).view(-1, self.embedding_dim, self.embedding_dim)\n",
    "        rel_t = self.right_relation_embeddings(indices=hr_batch[:, 1])\n",
    "        rel_t = rel_t.view(-1, 1, self.embedding_dim, self.embedding_dim)\n",
    "        t_all = self.entity_embeddings(indices=None).view(1, -1, self.embedding_dim, 1)\n",
    "\n",
    "        if slice_size is not None:\n",
    "            proj_t_arr = []\n",
    "            # Project entities\n",
    "            proj_h = rel_h @ h\n",
    "\n",
    "            for t in torch.split(t_all, slice_size, dim=1):\n",
    "                # Project entities\n",
    "                proj_t = rel_t @ t\n",
    "                proj_t_arr.append(proj_t)\n",
    "\n",
    "            proj_t = torch.cat(proj_t_arr, dim=1)\n",
    "\n",
    "        else:\n",
    "            # Project entities\n",
    "            proj_h = rel_h @ h\n",
    "            proj_t = rel_t @ t_all\n",
    "\n",
    "        scores = -torch.norm(proj_h[:, None, :, 0] - proj_t[:, :, :, 0], dim=-1, p=self.scoring_fct_norm)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def score_h(self, rt_batch: torch.LongTensor, slice_size: int = None) -> torch.FloatTensor:  # noqa: D102\n",
    "        # Get embeddings\n",
    "        h_all = self.entity_embeddings(indices=None).view(1, -1, self.embedding_dim, 1)\n",
    "        rel_h = self.left_relation_embeddings(indices=rt_batch[:, 0])\n",
    "        rel_h = rel_h.view(-1, 1, self.embedding_dim, self.embedding_dim)\n",
    "        rel_t = self.right_relation_embeddings(indices=rt_batch[:, 0]).view(-1, self.embedding_dim, self.embedding_dim)\n",
    "        t = self.entity_embeddings(indices=rt_batch[:, 1]).view(-1, self.embedding_dim, 1)\n",
    "\n",
    "        if slice_size is not None:\n",
    "            proj_h_arr = []\n",
    "\n",
    "            # Project entities\n",
    "            proj_t = rel_t @ t\n",
    "\n",
    "            for h in torch.split(h_all, slice_size, dim=1):\n",
    "                # Project entities\n",
    "                proj_h = rel_h @ h\n",
    "                proj_h_arr.append(proj_h)\n",
    "\n",
    "            proj_h = torch.cat(proj_h_arr, dim=1)\n",
    "        else:\n",
    "            # Project entities\n",
    "            proj_h = rel_h @ h_all\n",
    "            proj_t = rel_t @ t\n",
    "\n",
    "        scores = -torch.norm(proj_h[:, :, :, 0] - proj_t[:, None, :, 0], dim=-1, p=self.scoring_fct_norm)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 90])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "sparse tensors do not have strides",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-61628fda587e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     regularizer='LpRegularizer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/pipeline.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, training_loop, negative_sampler, negative_sampler_kwargs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0mresult_tracker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_tracker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mclear_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m     )\n\u001b[1;32m   1007\u001b[0m     \u001b[0mtraining_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers, clear_optimizer)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mresult_tracker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_tracker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0msub_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_size_probing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_memory_optimization\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_size_sufficient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;31m# return the relevant parameters slice_size and batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0msub_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_batch_and_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Create dummy result tracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36msub_batch_and_slice\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msub_batch_and_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;34m\"\"\"Check if sub-batching and/or slicing is necessary to train the model on the hardware at hand.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0msub_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupports_sub_batching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_batch_size_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;31m# If the sub_batch_size did not finish search with a possibility that fits the hardware, we have to try slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfinished_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_sub_batch_size_search\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_graph_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cudnn_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cuda_oom_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mruntime_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The batch_size {batch_size} was too big, sub_batching is required.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0msub_batch_size\u001b[0m \u001b[0;34m//=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_sub_batch_size_search\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_graph_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Trying batch_size {batch_size} for training now.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_size_probing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mruntime_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_graph_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers)\u001b[0m\n\u001b[1;32m    374\u001b[0m                         \u001b[0mcurrent_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                         \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                         \u001b[0mslice_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                     )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mslice_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         )\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sheaf_kg/lib/python3.7/site-packages/pykeen/training/slcwa.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Compute negative and positive scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mpositive_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_hrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mnegative_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_hrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-a142acabe70c>\u001b[0m in \u001b[0;36mscore_hrt\u001b[0;34m(self, hrt_batch)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mLv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: sparse tensors do not have strides"
     ]
    }
   ],
   "source": [
    "result2 = pipeline(\n",
    "    model=ModifiedSE,\n",
    "    dataset=dataset,\n",
    "    random_seed=1235,\n",
    "    device='cpu',\n",
    "    training_kwargs=dict(num_epochs=num_epochs, batch_size=10),\n",
    "    model_kwargs=dict(),\n",
    "    loss=loss,\n",
    "#     regularizer='LpRegularizer'\n",
    ")\n",
    "model2 = result2.model\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_models = ['StructuredEmbedding','TransE','RotatE','HolE']\n",
    "comp_results = []\n",
    "for comp_model in comp_models:\n",
    "    print('Running {}'.format(comp_model))\n",
    "    result = pipeline(\n",
    "        dataset=dataset,\n",
    "        model=comp_model,\n",
    "        random_seed=1235,\n",
    "        device='gpu',\n",
    "        training_kwargs=dict(num_epochs=num_epochs),  # Shouldn't take more than a minute or two on a nice computer\n",
    "        model_kwargs=dict(embedding_dim=embedding_dim),\n",
    "        loss=loss\n",
    "    )\n",
    "    comp_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(result2.losses)),result2.losses,label='Sheaf SE')\n",
    "for i in range(len(comp_models)):\n",
    "    comp_model = comp_models[i]\n",
    "    comp_result = comp_results[i]\n",
    "    plt.plot(np.arange(len(comp_result.losses)),comp_result.losses,label=comp_model)\n",
    "plt.ylabel(str(result.model.loss).replace('()',''))\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = result2.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compto = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['diff'] = res_df.Value - comp_results[compto].metric_results.to_df().Value\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_results[0].model.score_all_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.score_all_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
