{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.chdir('/home/gebhart/projects/sheaf_kg')\n",
    "import sheaf_kg.harmonic_extension as harmonic_extension\n",
    "# from sheaf_kg.train_sheafE_nonconstant_diag import ModifiedSE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FB15k'\n",
    "num_test = 1000\n",
    "path_lens = [2,3,4,5]\n",
    "model_name = 'StructuredEmbedding_1000epochs_64dim_SoftplusLossloss_42seed_20210128-1346'\n",
    "save_loc = '/home/gebhart/projects/sheaf_kg/data/{}/{}/trained_model.pkl'.format(dataset,model_name)\n",
    "model = torch.load(save_loc).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = pykeen.datasets.get_dataset(dataset=dataset)\n",
    "training = ds.training.mapped_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_hop_dataset(training, test_size, path_length):\n",
    "    ''' Function to random walk on knowledge graph triplets to generate\n",
    "    multi-hop testing dataset. This function assumes `training` is of the \n",
    "    form provided by pykeen. That is, a tensor of size (d x 3) where d \n",
    "    is the number of triplets, column 1 is the head entity id, column 2 \n",
    "    is the relation id, and column 3 is the tail entity id. \n",
    "    \n",
    "    There is likely a much faster way to generate this dataset with better \n",
    "    preprocessing and a better representation for the triplet graph. But \n",
    "    this should do for now.\n",
    "    '''\n",
    "    head_ents = torch.unique(training[:,0])\n",
    "    tail_ents = torch.unique(training[:,2])\n",
    "    unq_ents = torch.unique(torch.cat([head_ents,tail_ents]))\n",
    "    random_start_idxs = torch.randint(unq_ents.shape[0], (test_size,))\n",
    "    \n",
    "    path_ents = torch.zeros((test_size,path_length), dtype=torch.int64) # track nodes along random walk\n",
    "    comp_relations = torch.zeros((test_size,path_length), dtype=torch.int64) # track the relations crossed along each walk\n",
    "    inv_relations = torch.zeros((test_size,path_length), dtype=torch.int64) # track whether the crossed relations are inverted\n",
    "    for pidx in range(test_size):\n",
    "        random_start_idx = random_start_idxs[pidx]\n",
    "        ent = unq_ents[random_start_idx]\n",
    "        path_ents[pidx,0] = ent\n",
    "        for step in range(path_length):\n",
    "            head_instances = training[training[:,0] == ent]\n",
    "            tail_instances = training[training[:,2] == ent]\n",
    "            instances = torch.cat([head_instances, tail_instances])\n",
    "            random_step_idx = torch.randint(instances.shape[0], (1,))\n",
    "            step_edge = instances[random_step_idx[0]]\n",
    "            if step_edge[0] == ent:\n",
    "                # forward relation\n",
    "                inv_relations[pidx,step] = 1\n",
    "                ent = step_edge[2]\n",
    "            else:\n",
    "                # inverse relation\n",
    "                inv_relations[pidx,step] = -1\n",
    "                ent = step_edge[0]\n",
    "            path_ents[pidx,step] = ent\n",
    "            comp_relations[pidx,step] = step_edge[1]\n",
    "    return path_ents, comp_relations, inv_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Length: 2\n",
      "Path Length: 3\n",
      "Path Length: 4\n",
      "Path Length: 5\n"
     ]
    }
   ],
   "source": [
    "# all_results = []\n",
    "# hits_at = [1,3,5,10]\n",
    "# for pix in range(len(path_lens)):\n",
    "#     path_len = path_lens[pix]\n",
    "#     path_ents, comp_relations, inv_relations = create_multi_hop_dataset(training, num_test, path_len)\n",
    "#     results = np.zeros((path_ents.shape[0],len(hits_at)))\n",
    "#     for i in range(path_ents.shape[0]):\n",
    "#         path_ent = path_ents[i,:]\n",
    "#         comp_rel = comp_relations[i,:]\n",
    "#         inverses = inv_relations[i,:]\n",
    "\n",
    "#         source_ents = path_ent[:-1]\n",
    "\n",
    "#         # create edge indices as required by harmonic_extension.py, these are linear chains which index into path_ent\n",
    "#         edge_indices = np.concatenate([np.arange(0,path_ent.shape[0])[:,np.newaxis].T, np.arange(1,path_ent.shape[0]+1)[:,np.newaxis].T], axis=0)\n",
    "\n",
    "#         source_embeddings = model.entity_embeddings(indices=source_ents).view(-1, model.embedding_dim).detach().numpy()\n",
    "#         target_embeddings = model.entity_embeddings(indices=None).view(-1, model.embedding_dim).detach().numpy()\n",
    "\n",
    "#         left_restrictions = model.left_relation_embeddings(indices=comp_rel).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "#         right_restrictions = model.right_relation_embeddings(indices=comp_rel).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "\n",
    "#         restrictions = np.empty((comp_rel.shape[0], 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "#         for j in range(inverses.shape[0]):\n",
    "# #             if inverses[j] == -1:\n",
    "# #                 restrictions[j,0] = right_restrictions[j]\n",
    "# #                 restrictions[j,1] = left_restrictions[j]\n",
    "# #             else:\n",
    "# #                 restrictions[j,0] = left_restrictions[j]\n",
    "# #                 restrictions[j,1] = right_restrictions[j]\n",
    "                \n",
    "#             restrictions[j,0] = left_restrictions[j]\n",
    "#             restrictions[j,1] = right_restrictions[j]\n",
    "\n",
    "#         L = harmonic_extension.Laplacian(edge_indices, restrictions)\n",
    "\n",
    "#         source_vertices = np.arange(path_ent.shape[0]-1)\n",
    "#         target_vertices = [path_ent.shape[0]]\n",
    "#         Q = harmonic_extension.compute_costs(L,source_vertices,target_vertices,source_embeddings.flatten(),target_embeddings.T,source_embeddings.shape[1])\n",
    "#         ind = np.argpartition(Q, 10)[:10]\n",
    "#         sorted_ind = ind[np.argsort(Q[ind])]\n",
    "#         for kix in range(len(hits_at)):\n",
    "#             if np.isin(path_ent[-1], sorted_ind[:hits_at[kix]]):\n",
    "#                 results[i,kix] = 1.\n",
    "                \n",
    "#     all_results.append(results)\n",
    "\n",
    "all_results = []\n",
    "hits_at = [1,3,5,10]\n",
    "for pix in range(len(path_lens)):\n",
    "    path_len = path_lens[pix]\n",
    "    print('Path Length: {}'.format(path_len))\n",
    "    path_ents, comp_relations, inv_relations = create_multi_hop_dataset(training, num_test, path_len)\n",
    "    results = np.zeros((path_ents.shape[0],len(hits_at)))\n",
    "    for i in range(path_ents.shape[0]):\n",
    "        path_ent = path_ents[i,:]\n",
    "        comp_rel = comp_relations[i,:]\n",
    "        inverses = inv_relations[i,:]\n",
    "\n",
    "        source_ent = path_ent[0]\n",
    "\n",
    "        # create edge indices as required by harmonic_extension.py, these are linear chains which index into path_ent\n",
    "        edge_indices = np.concatenate([np.arange(0,path_ent.shape[0])[:,np.newaxis].T, np.arange(1,path_ent.shape[0]+1)[:,np.newaxis].T], axis=0)\n",
    "\n",
    "        source_embeddings = model.entity_embeddings(indices=source_ent).view(-1, model.embedding_dim).detach().numpy()\n",
    "        target_embeddings = model.entity_embeddings(indices=None).view(-1, model.embedding_dim).detach().numpy()\n",
    "\n",
    "        left_restrictions = model.left_relation_embeddings(indices=comp_rel).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "        right_restrictions = model.right_relation_embeddings(indices=comp_rel).view(-1, model.embedding_dim, model.embedding_dim).detach().numpy()\n",
    "\n",
    "        restrictions = np.empty((comp_rel.shape[0], 2, left_restrictions.shape[2], left_restrictions.shape[1]))\n",
    "        for j in range(inverses.shape[0]):\n",
    "            if inverses[j] == -1:\n",
    "                restrictions[j,0] = right_restrictions[j]\n",
    "                restrictions[j,1] = left_restrictions[j]\n",
    "            else:\n",
    "                restrictions[j,0] = left_restrictions[j]\n",
    "                restrictions[j,1] = right_restrictions[j]\n",
    "                \n",
    "#             restrictions[j,0] = left_restrictions[j]\n",
    "#             restrictions[j,1] = right_restrictions[j]\n",
    "\n",
    "        B = np.array([0,path_ent.shape[0]],np.int)\n",
    "        U = np.array(range(1,path_ent.shape[0]),np.int)\n",
    "        source_vertices = [0]\n",
    "        target_vertices = [1]\n",
    "        LSchur = harmonic_extension.Kron_reduction(edge_indices, restrictions, B, U)\n",
    "        Q = harmonic_extension.compute_costs(LSchur,source_vertices,target_vertices,source_embeddings.flatten(),target_embeddings.T,source_embeddings.shape[1])\n",
    "        ind = np.argpartition(Q, 10)[:10]\n",
    "        sorted_ind = ind[np.argsort(Q[ind])]\n",
    "        for kix in range(len(hits_at)):\n",
    "            if np.isin(path_ent[-1], sorted_ind[:hits_at[kix]]):\n",
    "                results[i,kix] = 1.\n",
    "                \n",
    "    all_results.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 2, Hits@1: 2.00%\n",
      "Length: 2, Hits@3: 5.30%\n",
      "Length: 2, Hits@5: 6.70%\n",
      "Length: 2, Hits@10: 8.20%\n",
      "Length: 3, Hits@1: 5.40%\n",
      "Length: 3, Hits@3: 10.00%\n",
      "Length: 3, Hits@5: 13.50%\n",
      "Length: 3, Hits@10: 16.80%\n",
      "Length: 4, Hits@1: 4.30%\n",
      "Length: 4, Hits@3: 7.80%\n",
      "Length: 4, Hits@5: 9.40%\n",
      "Length: 4, Hits@10: 12.20%\n",
      "Length: 5, Hits@1: 5.40%\n",
      "Length: 5, Hits@3: 10.70%\n",
      "Length: 5, Hits@5: 13.70%\n",
      "Length: 5, Hits@10: 18.00%\n"
     ]
    }
   ],
   "source": [
    "for pix in range(len(path_lens)):\n",
    "    results = all_results[pix]\n",
    "    for kix in range(len(hits_at)):\n",
    "        print('Length: {}, Hits@{}: {:.2f}%'.format(path_lens[pix], hits_at[kix], np.sum(results[:,kix])/results.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04275, 0.0845 , 0.10825, 0.138  ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(np.array(all_results), axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03575, 0.0635 , 0.078  , 0.1    ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(np.array(all_results), axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
